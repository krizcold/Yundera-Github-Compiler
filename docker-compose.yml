name: yunderagithubcompiler

services:
  yunderagithubcompiler:
    image: krizcold/yundera-github-compiler:latest
    container_name: yunderagithubcompiler
    restart: unless-stopped
    expose:
      - "3000"
    user: "root"
    entrypoint: ["/bin/sh"]
    command:
      - -c
      - |
        npm run setup
    environment:
      # Repository configuration (add REPO_0, REPO_1, etc. as needed)
      # REPO_0: "https://github.com/your-org/your-repo.git"
      # REPO_0_AUTOUPDATE: "true"
      
      # Application settings
      UPDATE_INTERVAL: "3600"
      FORCE_UPDATE_GLOBAL: "true"
      WEBUI_PORT: "3000"
      
      # CasaOS integration
      DEPLOYMENT_MODE: "appstore"
      CASAOS_API_HOST: "localhost"
      CASAOS_API_PORT: "8080"
      DATA_ROOT: $DATA_ROOT

    volumes:        
      # cloned repos
      - type: bind
        source: /DATA/AppData/yunderagithubcompiler/repos
        target: /app/repos

      # Mount DATA directory as read-only
      - type: bind
        source: /DATA
        target: /DATA
        read_only: true

      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock

    # Connect to the same network as the CasaOS service
    networks:
      - pcs
    
    # Add privileges to access CasaOS data (similar to CasaOS container)
    privileged: true
    
    # Add capabilities
    cap_add:
      - SYS_ADMIN
      - NET_ADMIN

    x-casaos:
      volumes:
        - container: /app/repos
          description:
            en_us: "Git repos are cloned here."

# Define the network as external, since it's created by the main NSL stack
networks:
  pcs:
    external: true

x-casaos:
  architectures:
    - amd64
    - arm64
  main: yunderagithubcompiler
  author: krizcold
  developer: krizcold
  icon: https://github.com/krizcold/Yundera-Github-Compiler/blob/main/YunderaCompiler.png?raw=true
  tagline:
    en_us: "Automatically build and deploy GitHub repos on Yundera"
  category: Utilities
  description:
    en_us: "Clone, build, and run Docker-based projects directly from GitHub URLs."
  title:
    en_us: "Yundera GitHub Compiler"
  store_app_id: yunderagithubcompiler
  is_uncontrolled: false
  index: /
  webui_port: 3000
  pre-install-cmd: |
    # Create a simplified watcher that waits for compose file and fixes docker.sock
    cat > /tmp/yundera-docker-sock-fixer.sh << 'EOF'
    #!/bin/bash
    echo "ðŸ”„ Yundera docker.sock fixer started at $(date)"
    
    COMPOSE_FILE="/DATA/AppData/casaos/apps/yunderagithubcompiler/docker-compose.yml"
    CONTAINER_NAME="yunderagithubcompiler"
    
    echo "ðŸ“ Target compose file: $COMPOSE_FILE"
    echo "ðŸ³ Target container: $CONTAINER_NAME"
    
    # Get Docker group ID from host system
    echo "ðŸ” Detecting Docker group ID..."
    if [ -S /var/run/docker.sock ]; then
      DOCKER_GID=$(stat -c '%g' /var/run/docker.sock)
      echo "âœ… Docker group ID detected: $DOCKER_GID"
    else
      echo "âŒ Docker socket not found on host, using fallback GID"
      DOCKER_GID=999  # Common fallback
    fi
    
    # Step 1: Wait for compose file to exist
    echo "ðŸ” Step 1: Waiting for compose file to exist..."
    counter=0
    max_wait=60  # 60 seconds max wait
    
    while [ $counter -lt $max_wait ]; do
      if [ -f "$COMPOSE_FILE" ]; then
        echo "âœ… Compose file exists after $counter seconds"
        break
      fi
      echo "â³ Compose file not found yet... (${counter}s/${max_wait}s)"
      sleep 1
      counter=$((counter + 1))
    done
    
    if [ ! -f "$COMPOSE_FILE" ]; then
      echo "âŒ Compose file not found after ${max_wait}s, exiting"
      exit 1
    fi
    
    # Step 2: Check if docker.sock is already mounted (EXCLUDING pre-install-cmd section)
    echo "ðŸ” Step 2: Checking docker.sock mount status in volumes section only..."
    
    # Extract only the service section (before x-casaos section)
    SERVICE_SECTION=$(awk '/^[[:space:]]*yunderagithubcompiler:/,/^[[:space:]]*x-casaos:/ {
      if (/^[[:space:]]*x-casaos:/) exit;
      print
    }' "$COMPOSE_FILE")
    
    echo "ðŸ“‹ Service section extracted for analysis:"
    echo "$SERVICE_SECTION"
    
    # Check if docker.sock is in the service volumes section
    if echo "$SERVICE_SECTION" | grep -q "/var/run/docker.sock:/var/run/docker.sock"; then
      echo "âœ… Docker.sock is already mounted in service volumes section"
    else
      echo "âŒ Docker.sock is NOT mounted in service volumes section"
      
      # Step 3: Add docker.sock mount
      echo "ðŸ”§ Step 3: Adding docker.sock mount to compose file..."
      
      # Backup original
      cp "$COMPOSE_FILE" "$COMPOSE_FILE.backup"
      echo "ðŸ“‹ Backed up compose file to $COMPOSE_FILE.backup"
      
      # Check if volumes section exists in service
      if echo "$SERVICE_SECTION" | grep -q "volumes:"; then
        echo "ðŸ“ Found existing volumes section in service"
        
        # Add docker.sock mount to compose file
        sed -i '/^[[:space:]]*volumes:/,/^[[:space:]]*networks:/ {
          /^[[:space:]]*read_only:[[:space:]]*true/ {
            a\            - type: bind\n              source: /var/run/docker.sock\n              target: /var/run/docker.sock
          }
        }' "$COMPOSE_FILE"
        
        # Add Docker group ID to environment variables
        echo "ðŸ”§ Adding Docker group ID to environment variables..."
        sed -i '/^[[:space:]]*environment:/,/^[[:space:]]*[^[:space:]]/ {
          /^[[:space:]]*WEBUI_PORT:/ {
            a\            DOCKER_GID: "'"$DOCKER_GID"'"
          }
        }' "$COMPOSE_FILE"
        
        echo "âœ… Added docker.sock mount to existing volumes section"
      else
        echo "ðŸ“ No volumes section found in service, adding one"
        
        # Add volumes section with docker.sock mount before networks
        sed -i '/^[[:space:]]*yunderagithubcompiler:/,/^[[:space:]]*networks:/ {
          /^[[:space:]]*networks:/ i\    volumes:\n        - type: bind\n          source: /var/run/docker.sock\n          target: /var/run/docker.sock\n
        }' "$COMPOSE_FILE"
        echo "âœ… Added volumes section with docker.sock mount"
      fi
      
      # Verify the change by checking service section again
      UPDATED_SERVICE_SECTION=$(awk '/^[[:space:]]*yunderagithubcompiler:/,/^[[:space:]]*x-casaos:/ {
        if (/^[[:space:]]*x-casaos:/) exit;
        print
      }' "$COMPOSE_FILE")
      
      echo "ðŸ“‹ Docker.sock mount and Docker group ID added successfully"
      
      # Check for docker.sock mount in the updated service section
      if echo "$UPDATED_SERVICE_SECTION" | grep -q "source: /var/run/docker.sock"; then
        echo "âœ… Docker.sock mount successfully added to service volumes section"
        
        # Also check if Docker group ID was added
        if grep -q "DOCKER_GID:" "$COMPOSE_FILE"; then
          echo "âœ… Docker group ID successfully added to environment variables"
        else
          echo "âš ï¸  Docker group ID might not have been added to environment"
        fi
      else
        echo "âŒ Failed to add docker.sock mount to service volumes section"
        exit 1
      fi
    fi
    
    # Step 4: Wait for container to be created
    echo "ðŸ” Step 4: Waiting for container to be created..."
    counter=0
    max_wait=30  # 30 seconds max wait
    
    while [ $counter -lt $max_wait ]; do
      if docker ps -a --filter "name=$CONTAINER_NAME" --format "{{.Names}}" | grep -q "^$CONTAINER_NAME$"; then
        echo "âœ… Container $CONTAINER_NAME found after $counter seconds"
        break
      fi
      echo "â³ Container not found yet... (${counter}s/${max_wait}s)"
      sleep 1
      counter=$((counter + 1))
    done
    
    if ! docker ps -a --filter "name=$CONTAINER_NAME" --format "{{.Names}}" | grep -q "^$CONTAINER_NAME$"; then
      echo "âŒ Container $CONTAINER_NAME not found after ${max_wait}s"
      echo "ðŸ“‹ Available containers:"
      docker ps -a --format "table {{.Names}}\t{{.Status}}\t{{.Image}}"
      exit 1
    fi
    
    # Step 5: Restart the container with new compose file
    echo "ðŸ”„ Step 5: Restarting container with updated compose file..."
    
    # Get container status
    CONTAINER_STATUS=$(docker ps -a --filter "name=$CONTAINER_NAME" --format "{{.Status}}")
    echo "ðŸ“Š Container status: $CONTAINER_STATUS"
    
    # Recreate container with updated compose file
    echo "ðŸ”„ Step 5: Recreating container with updated compose file..."
    
    # Stop and remove container
    echo "ðŸ›‘ Stopping container $CONTAINER_NAME..."
    docker stop "$CONTAINER_NAME" || echo "âš ï¸  Container might not be running"
    
    echo "ðŸ—‘ï¸  Removing container $CONTAINER_NAME..."
    docker rm "$CONTAINER_NAME" || echo "âš ï¸  Container might not exist"
    
    # Recreate with docker compose v2
    echo "ðŸš€ Recreating container with docker compose v2..."
    cd "/DATA/AppData/casaos/apps/yunderagithubcompiler"
    docker compose up -d
    
    # Verify the restart
    echo "âœ… Step 6: Verifying restart..."
    sleep 5
    
    NEW_STATUS=$(docker ps --filter "name=$CONTAINER_NAME" --format "{{.Status}}")
    if [ -n "$NEW_STATUS" ]; then
      echo "âœ… Container $CONTAINER_NAME is now running: $NEW_STATUS"
      
      # Check if docker.sock is actually mounted
      if docker exec "$CONTAINER_NAME" test -S /var/run/docker.sock 2>/dev/null; then
        echo "âœ… Docker.sock is successfully mounted and accessible in container"
      else
        echo "âŒ Docker.sock is NOT accessible in container"
      fi
    else
      echo "âŒ Container $CONTAINER_NAME is not running after restart"
    fi
    
    echo "ðŸ Watcher script completed at $(date)"
    EOF
    
    # Make it executable and run in background
    chmod +x /tmp/yundera-docker-sock-fixer.sh
    nohup /tmp/yundera-docker-sock-fixer.sh > /tmp/yundera-docker-sock-fixer.log 2>&1 &
    
    echo "ðŸš€ Docker.sock fixer launched, check logs at /tmp/yundera-docker-sock-fixer.log"
